# План работ: AI Mastering

## Этап 1: MVP — Ядро системы (от загрузки до скачивания)

**Цель**: Собрать минимально жизнеспособный E2E-цикл. Пользователь загружает трек, система его обрабатывает (пока просто), и пользователь может его скачать.

1.  **Инфраструктура и окружение (частично готово)**
    - `docker-compose`: Mongo, RabbitMQ, MinIO.
    - `Makefile` для удобного локального запуска (`up`, `api`, `worker`).
    - Конфигурация через `.env` файлы.
2.  **API: Загрузка и создание задачи**
    - `POST /uploads/presign`: (Готово) Генерация URL для прямой загрузки в S3.
      - **Добавить**: Валидация типа (`audio/wav`, `audio/aiff`) и размера файла на стороне API.
    - `POST /jobs`: Создание задачи на мастеринг.
      - Принимает `objectKey` загруженного файла (и референса, опционально).
      - Создаёт документ в MongoDB со статусом `queued`.
      - Отправляет сообщение с `jobId` в очередь RabbitMQ.
3.  **Воркер: Базовая обработка**
    - (Готово) Подписка на очередь.
    - Скачивание исходного трека из S3.
    - **MVP-процессинг**: Применение базовой цепочки FFmpeg (например, `loudnorm` для выравнивания громкости).
    - Загрузка результата (master.wav) и превью (preview.mp3) обратно в S3.
    - Обновление статуса задачи в MongoDB на `done` и сохранение ссылок на артефакты.
4.  **Frontend: Минимальный интерфейс**
    - Страница с drag-and-drop зоной для загрузки.
    - Отправка файла в S3, используя presigned URL.
    - После загрузки — вызов `POST /jobs` и переход на страницу задачи.
    - Страница задачи:
      - Отображение статуса (`pending`, `processing`, `done`, `failed`).
      - Реализовать через периодический опрос (polling) `GET /jobs/{jobId}`.
      - Когда `status=done`, появляется кнопка "Скачать".

---

## Этап 2: "Интеллект" и качество мастеринга

**Цель**: Улучшить качество обработки, добавить "умные" функции и дать пользователю больше контроля.

5.  **Глубокий анализ аудио**
    - Интеграция библиотек для анализа: LUFS, LRA, True Peak, Crest Factor, динамический диапазон.
    - Анализ частотного баланса по полосам (бас, середина, верха).
    - Детектирование базовых проблем: клиппинг, избыточный сайд-чейн.
    - Результат анализа сохраняется в `analysis.json` в S3 и привязывается к задаче.
6.  **Decision Engine v1 (на правилах)**
    - Разработка системы правил, которая на основе данных из `analysis.json` подбирает параметры для цепочки обработки.
    - _Примеры правил_:
      - Если Crest Factor низкий -> использовать экспандер.
      - Если много баса -> применить динамический эквалайзер.
    - Результат работы движка (`decision.json`) также сохраняется.
7.  **Продвинутая цепочка обработки**
    - Переход от простого `loudnorm` к модульной цепочке (EQ, компрессия, лимитер и т.д.) на основе Python-библиотек (`pydub`, `librosa`, etc).
    - Параметры для каждого модуля берутся из `decision.json`.
8.  **Мастеринг с референсом**
    - Возможность загрузить второй трек — референс.
    - Анализ референса (тональный баланс, громкость).
    - Алгоритм для применения характеристик референса к исходному треку (например, через match-EQ).

---

## Этап 3: Эксплуатация и надежность (Production-готовность)

**Цель**: Сделать сервис стабильным, отказоустойчивым и готовым к реальным нагрузкам.

9.  **Надежность очередей**
    - Настройка Dead-Letter-Exchange (DLX) для сообщений, которые не удалось обработать.
    - Механизм повторных попыток (retries) с экспоненциальной задержкой.
    - В MongoDB хранить `attempts` и `lastError` для отладки.
10. **Логирование и мониторинг**
    - Структурированное логирование во всех сервисах (API, воркер).
    - `request_id` для сквозной трассировки запросов.
    - Базовый дашборд для мониторинга (например, через OpenTelemetry + Grafana).
11. **Обработка ошибок и валидации**
    - На API: лимиты на длину трека, количество одновременных задач для пользователя.
    - В воркере: корректная обработка "битых" аудиофайлов и ошибок в процессе обработки. Статус задачи меняется на `failed` с понятным сообщением об ошибке.
12. **Тестирование**
    - Unit-тесты для ключевой бизнес-логики (анализ, decision engine).
    - E2E-тест: скрипт, который полностью имитирует пользователя (загрузка -> опрос статуса -> проверка результата).

---

## Этап 4: Пользовательский опыт и администрирование

**Цель**: Сделать продукт удобным для пользователя и управляемым для разработчика.

13. **Улучшения Frontend**
    - A/B-плеер для сравнения "до" и "после" с выравниванием громкости.
    - Визуализация отчёта по анализу трека.
    - Текстовое "AI-пояснение" на основе LLM, объясняющее, что было сделано с треком.
14. **Админ-панель/CLI**
    - Базовый интерфейс для просмотра списка задач, их статусов и ошибок.
    - CLI-инструменты для ручного перезапуска упавших задач или удаления старых данных.
15. **Подготовка к Production**
    - Единый S3-клиент, который может работать и с MinIO, и с облачными хранилищами (Backblaze B2, AWS S3).
    - Настройка CORS и CDN для раздачи контента.
